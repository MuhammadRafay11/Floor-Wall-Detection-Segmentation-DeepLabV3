{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO+FgQNJUYqgHsyGN/QOoVf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Mounting Drive to access Dataset"],"metadata":{"id":"hQ8N2AkE0JMA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qXiJmPUEXGx2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756028752987,"user_tz":-300,"elapsed":33426,"user":{"displayName":"p200018 Muhammad Rafay","userId":"01980898483406759677"}},"outputId":"47fa7263-084a-406e-8fd5-360492f29b7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["! pip install torch torchvision matplotlib\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iol53i1WXQ8x","executionInfo":{"status":"ok","timestamp":1756023218582,"user_tz":-300,"elapsed":8507,"user":{"displayName":"p200018 Muhammad Rafay","userId":"01980898483406759677"}},"outputId":"f47d0513-4664-4be7-b192-4b31a7f5f703"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"]}]},{"cell_type":"code","source":["!file /content/DatasetWF.zip\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8p5taNgl1SNr","executionInfo":{"status":"ok","timestamp":1756051615323,"user_tz":-300,"elapsed":125,"user":{"displayName":"p200018 Muhammad Rafay","userId":"01980898483406759677"}},"outputId":"4971712a-bc18-429f-95b8-626b7b9f300e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/DatasetWF.zip: Zip archive data, at least v2.0 to extract, compression method=deflate\n"]}]},{"cell_type":"code","source":["!ls -lh /content\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uc8SYdTT1U5h","executionInfo":{"status":"ok","timestamp":1756051635041,"user_tz":-300,"elapsed":125,"user":{"displayName":"p200018 Muhammad Rafay","userId":"01980898483406759677"}},"outputId":"cd6d6a93-5b5b-4058-8976-3634e3c5aaa6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 451M\n","-rw-r--r-- 1 root root 450M Aug 24 15:56 DatasetWF.zip\n","drwxr-xr-x 2 root root 4.0K Aug 24 15:59 DWF\n","drwxr-xr-x 1 root root 4.0K Aug 21 13:41 sample_data\n"]}]},{"cell_type":"code","source":["!ls /content/DatasetWF.zip\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u3HWFuml1dmV","executionInfo":{"status":"ok","timestamp":1756051662830,"user_tz":-300,"elapsed":120,"user":{"displayName":"p200018 Muhammad Rafay","userId":"01980898483406759677"}},"outputId":"f1eed511-18a0-464a-ba02-297fe635e549"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/DatasetWF.zip\n"]}]},{"cell_type":"code","source":["!unzip -q /content/DatasetWF.zip -d /content/DatasetWF\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-DxzUSnAciDO","executionInfo":{"status":"ok","timestamp":1756051708404,"user_tz":-300,"elapsed":119,"user":{"displayName":"p200018 Muhammad Rafay","userId":"01980898483406759677"}},"outputId":"edb5ef69-c0ad-4245-bb43-7db94c336e76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[/content/DatasetWF.zip]\n","  End-of-central-directory signature not found.  Either this file is not\n","  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n","  latter case the central directory and zipfile comment will be found on\n","  the last disk(s) of this archive.\n","unzip:  cannot find zipfile directory in one of /content/DatasetWF.zip or\n","        /content/DatasetWF.zip.zip, and cannot find /content/DatasetWF.zip.ZIP, period.\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","import cv2\n","import numpy as np\n","from pycocotools.coco import COCO\n","\n","\n","input_root = \"/content/drive/MyDrive/DWF\"\n","output_root = \"/content/drive/MyDrive/DatasetWF\"\n","splits = [\"train\", \"valid\", \"test\"]\n","\n","\n","def convert_split(split):\n","    split_in = os.path.join(input_root, split)\n","    split_out = os.path.join(output_root, split)\n","\n","\n","    ann_file = None\n","    for f in os.listdir(split_in):\n","        if f.endswith(\".json\"):\n","            ann_file = os.path.join(split_in, f)\n","            break\n","    if ann_file is None:\n","        print(f\" No JSON file found in {split_in}, skipping...\")\n","        return\n","\n","    img_dir = split_in\n","    img_out_dir = os.path.join(split_out, \"images\")\n","    mask_out_dir = os.path.join(split_out, \"masks\")\n","\n","    os.makedirs(img_out_dir, exist_ok=True)\n","    os.makedirs(mask_out_dir, exist_ok=True)\n","\n","    coco = COCO(ann_file)\n","\n","    for img_id in coco.getImgIds():\n","        img_info = coco.loadImgs(img_id)[0]\n","        file_name = img_info[\"file_name\"]\n","        height, width = img_info[\"height\"], img_info[\"width\"]\n","\n","\n","        mask = np.zeros((height, width), dtype=np.uint8)\n","\n","        ann_ids = coco.getAnnIds(imgIds=img_id)\n","        anns = coco.loadAnns(ann_ids)\n","\n","        for ann in anns:\n","            cat_id = ann[\"category_id\"]\n","            rle = coco.annToMask(ann)\n","            mask[rle == 1] = cat_id\n","\n","\n","        mask_path = os.path.join(mask_out_dir, file_name.replace(\".jpg\", \".png\"))\n","        cv2.imwrite(mask_path, mask)\n","\n","\n","        src_img = os.path.join(img_dir, file_name)\n","        dst_img = os.path.join(img_out_dir, file_name)\n","        if os.path.exists(src_img):\n","            shutil.copy(src_img, dst_img)\n","\n","    print(f\" {split} processed: {len(coco.getImgIds())} images\")\n","\n","\n","for split in splits:\n","    convert_split(split)\n","\n","print(\" All splits converted successfully at:\", output_root)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtONQHxHdCS7","executionInfo":{"status":"ok","timestamp":1756019703880,"user_tz":-300,"elapsed":862882,"user":{"displayName":"p200018 Muhammad Rafay","userId":"01980898483406759677"}},"outputId":"0015c82b-e586-4a4d-9f41-6973df45e3d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=58.06s)\n","creating index...\n","index created!\n"," train processed: 8392 images\n","loading annotations into memory...\n","Done (t=0.07s)\n","creating index...\n","index created!\n"," valid processed: 989 images\n","loading annotations into memory...\n","Done (t=0.04s)\n","creating index...\n","index created!\n"," test processed: 493 images\n"," All splits converted successfully at: /content/drive/MyDrive/DatasetWF\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","mask = cv2.imread(\"/content/drive/MyDrive/DatasetWF/train/masks/ADE_train_00000002_jpg.rf.c34b3e1c75afec24fe304e4325988598.png\", cv2.IMREAD_UNCHANGED)\n","print(\"Unique pixel values in mask:\", np.unique(mask))"],"metadata":{"id":"q3snGJMkgsgz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756020843628,"user_tz":-300,"elapsed":314,"user":{"displayName":"p200018 Muhammad Rafay","userId":"01980898483406759677"}},"outputId":"a2564a63-a010-4a9e-a7c7-178743252d37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique pixel values in mask: [0 1 2]\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","\n","mask_dir = \"/content/drive/MyDrive/DatasetWF/train/masks\"\n","\n","all_classes = set()\n","\n","for fname in os.listdir(mask_dir):\n","    if fname.endswith(\".png\"):\n","        mask = cv2.imread(os.path.join(mask_dir, fname), cv2.IMREAD_UNCHANGED)\n","        unique_vals = np.unique(mask)\n","        all_classes.update(unique_vals.tolist())\n","\n","print(\"Unique class IDs in masks:\", sorted(all_classes))\n","print(\"Number of classes (including background):\", len(all_classes))\n"],"metadata":{"id":"5Wce89qOA7CL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import torch\n","from torch.utils.data import Dataset\n","\n","class SegmentationDataset(Dataset):\n","    def __init__(self, img_dir, mask_dir, transforms=None):\n","        self.img_dir = img_dir\n","        self.mask_dir = mask_dir\n","        self.imgs = sorted(os.listdir(img_dir))\n","        self.masks = sorted(os.listdir(mask_dir))\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.imgs)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.imgs[idx])\n","        mask_path = os.path.join(self.mask_dir, self.masks[idx])\n","\n","        image = Image.open(img_path).convert(\"RGB\")\n","        mask = Image.open(mask_path)\n","\n","        # Convert to tensor\n","        image = torch.tensor(np.array(image)).permute(2,0,1).float() / 255.0\n","        mask = torch.tensor(np.array(mask)).long()\n","\n","        if self.transforms:\n","            image, mask = self.transforms(image, mask)\n","\n","        return image, mask\n"],"metadata":{"id":"bXKEj0NK_x2q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pgU_vL_2A5Yy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchvision\n","from torch import nn\n","\n","model = torchvision.models.segmentation.deeplabv3_mobilenet_v3_large(pretrained=True)\n","\n","\n","num_classes = 3\n","model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fgpZAGkpAPMZ","executionInfo":{"status":"ok","timestamp":1756035224575,"user_tz":-300,"elapsed":1809,"user":{"displayName":"p200018 Muhammad Rafay","userId":"01980898483406759677"}},"outputId":"99ff6c08-dd6a-4077-924a-83dd5fb4426a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_MobileNet_V3_Large_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","source":["print(\"CUDA available:\", torch.cuda.is_available())\n","print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ym2P5r-de-nV","executionInfo":{"status":"ok","timestamp":1756035226820,"user_tz":-300,"elapsed":172,"user":{"displayName":"p200018 Muhammad Rafay","userId":"01980898483406759677"}},"outputId":"837f94e7-61e0-45d1-f18a-f3bd720ad457"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA available: True\n","GPU name: Tesla T4\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","\n","# dataset paths\n","train_dataset = SegmentationDataset(\"/content/drive/MyDrive/DatasetWF/train/images\",\n","                                    \"/content/drive/MyDrive/DatasetWF/train/masks\")\n","val_dataset = SegmentationDataset(\"/content/drive/MyDrive/DatasetWF/valid/images\",\n","                                  \"/content/drive/MyDrive/DatasetWF/valid/masks\")\n","\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=2)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"],"metadata":{"id":"gZcfpq-BHKNJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(model, loader, optimizer, device):\n","    model.train()\n","    total_loss = 0\n","    for imgs, masks in loader:\n","        imgs, masks = imgs.to(device), masks.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(imgs)['out']\n","        loss = F.cross_entropy(outputs, masks)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(loader)\n","\n","def evaluate(model, loader, device):\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():\n","        for imgs, masks in loader:\n","            imgs, masks = imgs.to(device), masks.to(device)\n","            outputs = model(imgs)['out']\n","            loss = F.cross_entropy(outputs, masks)\n","            total_loss += loss.item()\n","    return total_loss / len(loader)\n"],"metadata":{"id":"d5fBmQW-IPUt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 20\n","for epoch in range(num_epochs):\n","    train_loss = train_one_epoch(model, train_loader, optimizer, device)\n","    val_loss = evaluate(model, val_loader, device)\n","    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n","\n","torch.save(model.state_dict(), \"/content/drive/MyDrive/deeplabv3_mobilenet_finetuned.pth\")\n"],"metadata":{"id":"_zHENWr5IjCH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"n3d-PB7_JfsP"},"execution_count":null,"outputs":[]}]}