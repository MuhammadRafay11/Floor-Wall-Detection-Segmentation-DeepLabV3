{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQ8N2AkE0JMA"
   },
   "source": [
    "# Mounting Drive to access Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33426,
     "status": "ok",
     "timestamp": 1756028752987,
     "user": {
      "displayName": "p200018 Muhammad Rafay",
      "userId": "01980898483406759677"
     },
     "user_tz": -300
    },
    "id": "qXiJmPUEXGx2",
    "outputId": "47fa7263-084a-406e-8fd5-360492f29b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8507,
     "status": "ok",
     "timestamp": 1756023218582,
     "user": {
      "displayName": "p200018 Muhammad Rafay",
      "userId": "01980898483406759677"
     },
     "user_tz": -300
    },
    "id": "Iol53i1WXQ8x",
    "outputId": "f47d0513-4664-4be7-b192-4b31a7f5f703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and Convertion xml Annotations to Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 862882,
     "status": "ok",
     "timestamp": 1756019703880,
     "user": {
      "displayName": "p200018 Muhammad Rafay",
      "userId": "01980898483406759677"
     },
     "user_tz": -300
    },
    "id": "DtONQHxHdCS7",
    "outputId": "0015c82b-e586-4a4d-9f41-6973df45e3d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=58.06s)\n",
      "creating index...\n",
      "index created!\n",
      " train processed: 8392 images\n",
      "loading annotations into memory...\n",
      "Done (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      " valid processed: 989 images\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      " test processed: 493 images\n",
      " All splits converted successfully at: /content/drive/MyDrive/DatasetWF\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "input_root = \"/content/drive/MyDrive/DWF\"\n",
    "output_root = \"/content/drive/MyDrive/DatasetWF\"\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "\n",
    "def convert_split(split):\n",
    "    split_in = os.path.join(input_root, split)\n",
    "    split_out = os.path.join(output_root, split)\n",
    "\n",
    "\n",
    "    ann_file = None\n",
    "    for f in os.listdir(split_in):\n",
    "        if f.endswith(\".json\"):\n",
    "            ann_file = os.path.join(split_in, f)\n",
    "            break\n",
    "    if ann_file is None:\n",
    "        print(f\" No JSON file found in {split_in}, skipping...\")\n",
    "        return\n",
    "\n",
    "    img_dir = split_in\n",
    "    img_out_dir = os.path.join(split_out, \"images\")\n",
    "    mask_out_dir = os.path.join(split_out, \"masks\")\n",
    "\n",
    "    os.makedirs(img_out_dir, exist_ok=True)\n",
    "    os.makedirs(mask_out_dir, exist_ok=True)\n",
    "\n",
    "    coco = COCO(ann_file)\n",
    "\n",
    "    for img_id in coco.getImgIds():\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        file_name = img_info[\"file_name\"]\n",
    "        height, width = img_info[\"height\"], img_info[\"width\"]\n",
    "\n",
    "\n",
    "        mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "        for ann in anns:\n",
    "            cat_id = ann[\"category_id\"]\n",
    "            rle = coco.annToMask(ann)\n",
    "            mask[rle == 1] = cat_id\n",
    "\n",
    "\n",
    "        mask_path = os.path.join(mask_out_dir, file_name.replace(\".jpg\", \".png\"))\n",
    "        cv2.imwrite(mask_path, mask)\n",
    "\n",
    "\n",
    "        src_img = os.path.join(img_dir, file_name)\n",
    "        dst_img = os.path.join(img_out_dir, file_name)\n",
    "        if os.path.exists(src_img):\n",
    "            shutil.copy(src_img, dst_img)\n",
    "\n",
    "    print(f\" {split} processed: {len(coco.getImgIds())} images\")\n",
    "\n",
    "\n",
    "for split in splits:\n",
    "    convert_split(split)\n",
    "\n",
    "print(\" All splits converted successfully at:\", output_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1756020843628,
     "user": {
      "displayName": "p200018 Muhammad Rafay",
      "userId": "01980898483406759677"
     },
     "user_tz": -300
    },
    "id": "q3snGJMkgsgz",
    "outputId": "a2564a63-a010-4a9e-a7c7-178743252d37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique pixel values in mask: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mask = cv2.imread(\"/content/drive/MyDrive/DatasetWF/train/masks/ADE_train_00000002_jpg.rf.c34b3e1c75afec24fe304e4325988598.png\", cv2.IMREAD_UNCHANGED)\n",
    "print(\"Unique pixel values in mask:\", np.unique(mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1809,
     "status": "ok",
     "timestamp": 1756035224575,
     "user": {
      "displayName": "p200018 Muhammad Rafay",
      "userId": "01980898483406759677"
     },
     "user_tz": -300
    },
    "id": "fgpZAGkpAPMZ",
    "outputId": "99ff6c08-dd6a-4077-924a-83dd5fb4426a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_MobileNet_V3_Large_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "model = torchvision.models.segmentation.deeplabv3_mobilenet_v3_large(pretrained=True)\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 172,
     "status": "ok",
     "timestamp": 1756035226820,
     "user": {
      "displayName": "p200018 Muhammad Rafay",
      "userId": "01980898483406759677"
     },
     "user_tz": -300
    },
    "id": "Ym2P5r-de-nV",
    "outputId": "837f94e7-61e0-45d1-f18a-f3bd720ad457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZcfpq-BHKNJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# dataset paths\n",
    "train_dataset = SegmentationDataset(\"/content/drive/MyDrive/DatasetWF/train/images\",\n",
    "                                    \"/content/drive/MyDrive/DatasetWF/train/masks\")\n",
    "val_dataset = SegmentationDataset(\"/content/drive/MyDrive/DatasetWF/valid/images\",\n",
    "                                  \"/content/drive/MyDrive/DatasetWF/valid/masks\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate F(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5fBmQW-IPUt"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for imgs, masks in loader:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)['out']\n",
    "        loss = F.cross_entropy(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            outputs = model(imgs)['out']\n",
    "            loss = F.cross_entropy(outputs, masks)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning (20 Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zHENWr5IjCH"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, device)\n",
    "    val_loss = evaluate(model, val_loader, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"/content/drive/MyDrive/deeplabv3_mobilenet_finetuned.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3d-PB7_JfsP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO+FgQNJUYqgHsyGN/QOoVf",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
